Miscellaneous advice
====================

Sequencing depth and number of samples
--------------------------------------

`Hart et al. (2013)
<http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3842884/>`__ provides a
nice description and a set of tools for estimating your needed
sequencing depth and number of samples.  They provide an `Excel based
calculator
<http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3842884/bin/supp_data.zip>`__
for calculating number of samples.  Their numbers are surprisingly
large to me ;).

In a proposal for an exploratory effort to discover differentially
expressed genes, I would suggest 3-5 biological replicates with 30-50
million reads each.  More reads is usually cheaper than more replicates,
so 50-100m reads may give you more power to resolve smaller fold changes.

Developing your own pipeline
----------------------------

1. Start with someone else's approach; don't design your own.  There
   are lots of partly done examples that you can find on the Web.

2. Generate a data subset (the first few 100k reads, for example).

2. Run commands interactively on an HPC dev node until you get all of
   the commands basically working; track all of your commands in a
   Word document or some such.

3. Once you have a set of commands that seems to work on small data,
   write a script.  Run the script on the small data again; make sure
   that works.

4. Turn it into a qsub script (making sure you're in the right 
   directory, have the modules loaded, etc.)

5. Make sure the qsub script works on your same small data.

6. Scale up to a big test data set.

7. Once that's all working, SAVE THE SCRIPT SOMEWHERE.  Then,
   edit it to work on all your data sets (you may want to make subsets
   again, as much as possible).

8. Provide your scripts and raw counts files as part of any publication
   or thesis, perhaps via `figshare <http://figshare.com>`__.